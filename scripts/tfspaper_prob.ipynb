{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as col\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy.stats import permutation_test\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import ttest_ind, ttest_rel, permutation_test\n",
    "from statsmodels.stats import multitest\n",
    "\n",
    "from tfsemb_class import tsne, save_pickle, add_speech\n",
    "from tfsplt_encoding import get_cmap_smap, aggregate_data, organize_data\n",
    "from tfsplt_utils import read_folder, load_pickle, get_con_color\n",
    "from tfsplt_brainmap import get_sigelecs, Colorbar, make_brainmap\n",
    "from tfsplt_brainmap_cat import make_brainmap_cat\n",
    "\n",
    "plt.style.use('/scratch/gpfs/ln1144/247-plotting/scripts/paper.mlpstyle')\n",
    "plt.style.use('../data/plotting/paper-prob-improb/paper.mlpstyle')\n",
    "ls = '-'\n",
    "lw = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sig tests\n",
    "def fdr(pvals):\n",
    "    _, pcor, _, _ = multitest.multipletests(\n",
    "        pvals, method=\"fdr_bh\", is_sorted=False\n",
    "    )\n",
    "    return pcor\n",
    "\n",
    "blu_list = get_con_color(\"Blues\",1000)\n",
    "red_list = get_con_color(\"Reds\",1000)\n",
    "ora_list = get_con_color(\"Oranges\",1000)\n",
    "pur_list = get_con_color(\"Purples\",1000)\n",
    "gre_list = get_con_color(\"Greens\",1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sig Elec Files (for ROIs)\n",
    "sig_df_whisper = pd.read_csv(\"../data/plotting/paper-whisper/data/base_df.csv\")\n",
    "\n",
    "sig_df_gpt2 = pd.read_csv(\"../data/plotting/sig-elecs/20230723-tfs-sig-file/tfs-sig-file.csv\").iloc[:,1:]\n",
    "sig_df_gpt2.rename(columns={\"patient\":\"sid\",\"electrode\":\"elec_1\",\"prod_significant\":\"gpt2-prod\",\"comp_significant\":\"gpt2-comp\"},inplace=True)\n",
    "sig_df_gpt2 = sig_df_gpt2.loc[sig_df_gpt2.model == \"glove\",(\"sid\",\"elec_1\",\"gpt2-prod\",\"gpt2-comp\")]\n",
    "\n",
    "sig_df = sig_df_whisper.merge(sig_df_gpt2,how=\"left\",on=[\"sid\",\"elec_1\"])\n",
    "sig_df = sig_df.fillna({\"gpt2-comp\":False,\"gpt2-prod\":False})\n",
    "sig_df[\"electrode\"] = sig_df.sid.astype(str) + \"_\" + sig_df.elec_1\n",
    "\n",
    "# Split IFG areas\n",
    "sig_df.loc[(sig_df.roi_1 == \"IFG\") & (sig_df.NYU_roi == \"parsopercularis\"),\"roi_1\"] = \"BA44\"\n",
    "sig_df.loc[(sig_df.roi_1 == \"IFG\") & (sig_df.NYU_roi == \"parstriangularis\"),\"roi_1\"] = \"BA45\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align prod/comp elecs\n",
    "sig_df.loc[sig_df[\"gpt2-prod\"], \"gpt2-comp\"] = True\n",
    "sig_df.loc[sig_df[\"gpt2-comp\"], \"gpt2-prod\"] = True\n",
    "print(len(sig_df[sig_df[\"gpt2-prod\"]]), len(sig_df[sig_df[\"gpt2-comp\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prob-improb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  project = \"tfs\"\n",
    "  formats = [ # encoding folder\n",
    "    # \"../data/encoding/tfs/20230227-gpt2-preds/kw-tfs-full-%s-glove50-lag10k-25-gpt2-xl-prob/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230227-gpt2-preds/kw-tfs-full-%s-glove50-lag10k-25-gpt2-xl-improb/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230809-gpt2-preds/kw-tfs-full-%s-gpt2-xl-glove50-lag10k-25-prob/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230809-gpt2-preds/kw-tfs-full-%s-gpt2-xl-glove50-lag10k-25-improb/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20230809-gpt2-preds/kw-tfs-full-%s-gpt2-xl-glove50-lag10k-25-aligned-prob/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20230809-gpt2-preds/kw-tfs-full-%s-gpt2-xl-glove50-lag10k-25-aligned-improb/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230809-gpt2-preds/kw-tfs-full-%s-gpt2-xl-glove50-lag10k-25-alignednum2-prob/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230809-gpt2-preds/kw-tfs-full-%s-gpt2-xl-glove50-lag10k-25-alignednum2-improb/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230820-gpt2-preds-static/kw-tfs-full-%s-gpt2-xl-shift-emb-lag10k-25-static-prob/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230820-gpt2-preds-static/kw-tfs-full-%s-gpt2-xl-shift-emb-lag10k-25-static-improb/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230820-gpt2-preds-static/kw-tfs-full-%s-gpt2-xl-shift-emb-lag10k-25-static-aligned-prob/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230820-gpt2-preds-static/kw-tfs-full-%s-gpt2-xl-shift-emb-lag10k-25-static-aligned-improb/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230820-gpt2-preds-static/kw-tfs-full-%s-gpt2-xl-shift-emb-lag10k-25-static-alignednum-prob/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230820-gpt2-preds-static/kw-tfs-full-%s-gpt2-xl-shift-emb-lag10k-25-static-alignednum-improb/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230817-glove-concats/kw-tfs-full-%s-gpt2-xl-glove50-concat-emb4-lag10k-25-prob2/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230817-glove-concats/kw-tfs-full-%s-gpt2-xl-glove50-concat-emb4-lag10k-25-improb2/*/*%s.csv\",\n",
    "  ]\n",
    "  labels = [\n",
    "    \"prob\",\n",
    "    \"improb\"\n",
    "  ]\n",
    "  sig_elec_file = [\"../data/plotting/sig-elecs/20230723-tfs-sig-file/tfs-sig-file-glove-%(sid)s-%(key)s.csv\"]\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  layers = np.arange(0,25)\n",
    "  lags_plot = np.arange(-10000,10001,25) # encoding lags\n",
    "  lags_show = np.arange(-2000,2001,25) # lags for the effect\n",
    "  lc_by = \"labels\"\n",
    "  ls_by = \"keys\"\n",
    "\n",
    "# Aggregate Data\n",
    "args = Args()\n",
    "args.unique_labels = list(dict.fromkeys(args.labels))\n",
    "args.unique_keys = list(dict.fromkeys(args.keys))\n",
    "args.lags_show = args.lags_show / 1000\n",
    "args.lags_plot = args.lags_plot / 1000\n",
    "args = get_sigelecs(args)  # get significant electrodes\n",
    "\n",
    "# for item in args.sigelecs: # align prod/comp elecs\n",
    "#     comp_set = set(args.sigelecs[(item[0], \"comp\")])\n",
    "#     prod_set = set(args.sigelecs[(item[0], \"prod\")])\n",
    "#     args.sigelecs[item] = comp_set.union(prod_set)\n",
    "\n",
    "df = aggregate_data(args) # aggregate data\n",
    "df = organize_data(args, df) # trim data if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual vs Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  project = \"tfs\"\n",
    "  formats = [ # encoding folder\n",
    "    # \"../data/encoding/tfs/20230817-glove-concats/kw-tfs-full-%s-glove50-concat-emb4-lag10k-25-all/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230824-gpt2-predict/kw-tfs-full-%s-gpt2-xl-glove50-predict5-lag10k-25-all/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230817-glove-concats/kw-tfs-full-%s-gpt2-xl-glove50-concat-emb4-lag10k-25-improb2/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230824-gpt2-predict/kw-tfs-full-%s-gpt2-xl-glove50-predict5-lag10k-25-improb/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20230809-gpt2-preds/kw-tfs-full-%s-gpt2-xl-glove50-lag10k-25-improb/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20230824-gpt2-predict/kw-tfs-full-%s-gpt2-xl-glove50-predict-lag10k-25-improb/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230809-gpt2-preds/kw-tfs-full-%s-gpt2-xl-glove50-lag10k-25-aligned-improb/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20230824-gpt2-predict/kw-tfs-full-%s-gpt2-xl-glove50-predict-lag10k-25-aligned-improb/*/*%s.csv\",\n",
    "  ]\n",
    "  labels = [\n",
    "    \"actual\",\n",
    "    \"pred\"\n",
    "  ]\n",
    "  sig_elec_file = [\"../data/plotting/sig-elecs/20230723-tfs-sig-file/tfs-sig-file-glove-%(sid)s-%(key)s.csv\"]\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  layers = np.arange(0,25)\n",
    "  lags_plot = np.arange(-10000,10001,25) # encoding lags\n",
    "  lags_show = np.arange(-2000,2001,25) # lags for the effect\n",
    "  lc_by = \"labels\"\n",
    "  ls_by = \"keys\"\n",
    "\n",
    "# Aggregate Data\n",
    "args = Args()\n",
    "args.unique_labels = list(dict.fromkeys(args.labels))\n",
    "args.unique_keys = list(dict.fromkeys(args.keys))\n",
    "args.lags_show = args.lags_show / 1000\n",
    "args.lags_plot = args.lags_plot / 1000\n",
    "args = get_sigelecs(args)  # get significant electrodes\n",
    "\n",
    "# for item in args.sigelecs: # align prod/comp elecs\n",
    "#     comp_set = set(args.sigelecs[(item[0], \"comp\")])\n",
    "#     prod_set = set(args.sigelecs[(item[0], \"prod\")])\n",
    "#     args.sigelecs[item] = comp_set.union(prod_set)\n",
    "\n",
    "df = aggregate_data(args) # aggregate data\n",
    "df = organize_data(args, df) # trim data if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glove Concats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating data\n",
      "Trimming Data\n"
     ]
    }
   ],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  project = \"tfs\"\n",
    "  formats = [ # encoding folder\n",
    "    \"../data/encoding/tfs/20230817-glove-concats/kw-tfs-full-%s-glove50--lag10k-25-all/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20230817-glove-concats/kw-tfs-full-%s-glove50-concat-emb1-lag10k-25-all/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20230817-glove-concats/kw-tfs-full-%s-glove50-concat-emb2-lag10k-25-all/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20230817-glove-concats/kw-tfs-full-%s-glove50-concat-emb3-lag10k-25-all/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20230817-glove-concats/kw-tfs-full-%s-glove50-concat-emb4-lag10k-25-all/*/*%s.csv\",\n",
    "  ]\n",
    "  labels = [\n",
    "    \"n\",\n",
    "    \"n+1\",\n",
    "    \"n+2\",\n",
    "    \"n+3\",\n",
    "    \"n+4\",\n",
    "  ]\n",
    "  sig_elec_file = [\"../data/plotting/sig-elecs/20230723-tfs-sig-file/tfs-sig-file-glove-%(sid)s-%(key)s.csv\"]\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  layers = np.arange(0,25)\n",
    "  lags_plot = np.arange(-10000,10001,25) # encoding lags\n",
    "  lags_show = np.arange(-2000,2001,25) # lags for the effect\n",
    "  lc_by = \"labels\"\n",
    "  ls_by = \"keys\"\n",
    "\n",
    "# Aggregate Data\n",
    "args = Args()\n",
    "args.unique_labels = list(dict.fromkeys(args.labels))\n",
    "args.unique_keys = list(dict.fromkeys(args.keys))\n",
    "args.lags_show = args.lags_show / 1000\n",
    "args.lags_plot = args.lags_plot / 1000\n",
    "args = get_sigelecs(args)  # get significant electrodes\n",
    "\n",
    "# for item in args.sigelecs: # align prod/comp elecs\n",
    "#     comp_set = set(args.sigelecs[(item[0], \"comp\")])\n",
    "#     prod_set = set(args.sigelecs[(item[0], \"prod\")])\n",
    "#     args.sigelecs[item] = comp_set.union(prod_set)\n",
    "\n",
    "df = aggregate_data(args) # aggregate data\n",
    "df = organize_data(args, df) # trim data if necessary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_lags(args, df, label1, label2, threshold):\n",
    "    sig_lags = {}\n",
    "    for key in args.keys:\n",
    "        df_key = df[df.index.get_level_values(\"key\") == key]\n",
    "        df_prob = df_key[df_key.index.get_level_values(\"label\") == label1]\n",
    "        df_improb = df_key[df_key.index.get_level_values(\"label\") == label2]\n",
    "        # df_prob.sort_values([(\"electrode\")], ascending=True, inplace=True)\n",
    "        # df_improb.sort_values([(\"electrode\")], ascending=True, inplace=True)\n",
    "\n",
    "        ts = []\n",
    "        rs = []\n",
    "        for df_col in np.arange(0,df_prob.shape[1]):\n",
    "            r = ttest_ind(df_prob.iloc[:,df_col], df_improb.iloc[:,df_col],alternative=\"two-sided\")\n",
    "            ts.append(r[0])\n",
    "            rs.append(r[1])\n",
    "        rs = fdr(rs)\n",
    "\n",
    "        sig_lags[f\"{key}_{label1}\"] = [args.lags_show[idx] for (idx, r) in enumerate(rs) if (ts[idx] > 0 and r < threshold)]\n",
    "        sig_lags[f\"{key}_{label2}\"] = [args.lags_show[idx] for (idx, r) in enumerate(rs) if (ts[idx] < 0 and r < threshold)]\n",
    "    return sig_lags\n",
    "\n",
    "\n",
    "def statistic(x, y, axis):\n",
    "    return np.mean(x, axis=axis) - np.mean(y, axis=axis)\n",
    "\n",
    "\n",
    "def get_sig(args, df1, df2, lags, threshold, color1, color2):\n",
    "    lags = [lag / 1000 for lag in lags]\n",
    "    lags_idx = [lag_idx for lag_idx, lag in enumerate(args.lags_plot) if lag in lags]\n",
    "    r = ttest_rel(df1.loc[:,lags_idx].mean(), df2.loc[:,lags_idx].mean(),alternative=\"two-sided\")\n",
    "\n",
    "    if r[1] < threshold:\n",
    "        if r[0] > 0:\n",
    "            return color1\n",
    "        elif r[0] < 0:\n",
    "            return color2\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_sigs(args, df, label1, label2, threshold, color1, color2):\n",
    "    sig_lags = {}\n",
    "    df = df.sort_values([(\"electrode\")], ascending=True)\n",
    "    for key in args.keys:\n",
    "        df_key = df[df.index.get_level_values(\"key\") == key]\n",
    "        df_prob = df_key[df_key.index.get_level_values(\"label\") == label1]\n",
    "        df_improb = df_key[df_key.index.get_level_values(\"label\") == label2]\n",
    "\n",
    "        lags_show = np.arange(-500, -99, 25) # lags for the effect\n",
    "        sig_result = get_sig(args, df_prob, df_improb, lags_show, threshold, color1, color2)\n",
    "        if sig_result:\n",
    "            sig_lags[(key), -0.4] = sig_result\n",
    "\n",
    "        lags_show = np.arange(100, 501, 25) # lags for the effect\n",
    "        lags_show = np.arange(200, 601, 25) # lags for the effect\n",
    "        sig_result = get_sig(args, df_prob, df_improb, lags_show, threshold, color1, color2)\n",
    "        if sig_result:\n",
    "            sig_lags[(key), 0.4] = sig_result\n",
    "\n",
    "    return sig_lags\n",
    "\n",
    "\n",
    "def get_sig_perm(args, df1, df2, lags, threshold, color1, color2):\n",
    "    lags = [lag / 1000 for lag in lags]\n",
    "    lags_idx = [lag_idx for lag_idx, lag in enumerate(args.lags_plot) if lag in lags]\n",
    "    samples_1 = df1.loc[:,lags_idx].to_numpy().ravel()\n",
    "    samples_2 = df2.loc[:,lags_idx].to_numpy().ravel()\n",
    "\n",
    "    r = permutation_test(\n",
    "        (samples_1, samples_2),\n",
    "            statistic=statistic,\n",
    "            vectorized=True,\n",
    "            n_resamples=10000,\n",
    "            alternative=\"two-sided\",\n",
    "            permutation_type=\"samples\",\n",
    "        )\n",
    "\n",
    "    if r.pvalue < threshold:\n",
    "        if r.statistic > 0:\n",
    "            return color1\n",
    "        elif r.statistic < 0:\n",
    "            # return \"purple\"\n",
    "            return color2\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_sigs_perm(args, df, label1, label2, threshold, color1, color2):\n",
    "    sig_lags = {}\n",
    "    for key in args.keys:\n",
    "        df_key = df[df.index.get_level_values(\"key\") == key]\n",
    "        df_prob = df_key[df_key.index.get_level_values(\"label\") == label1]\n",
    "        df_improb = df_key[df_key.index.get_level_values(\"label\") == label2]\n",
    "            \n",
    "        lags_show = np.arange(-500, -99, 25) # lags for the effect\n",
    "        sig_result = get_sig_perm(args, df_prob, df_improb, lags_show, threshold, color1, color2)\n",
    "        if sig_result:\n",
    "            sig_lags[(key), -0.3] = sig_result\n",
    "\n",
    "        # lags_show = np.arange(100, 501, 25) # lags for the effect\n",
    "        # lags_show = np.arange(200, 601, 25) # lags for the effect\n",
    "        # sig_result = get_sig_perm(args, df_prob, df_improb, lags_show, threshold)\n",
    "        # if sig_result:\n",
    "        #     sig_lags[(key), 0.3] = sig_result\n",
    "\n",
    "    return sig_lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Plot Prob-improb (Whole Brain and ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average encoding plots\n",
    "def average_encoding(args, df, tag, color1, color2):\n",
    "    sig_lags = get_sigs(args, df, \"prob\", \"improb\", 0.001, color1, color2)\n",
    "    # sig_lags2 = get_sig_lags(args, df, \"prob\", \"improb\", 0.01)\n",
    "    axes = [\"comp\",\"prod\"]\n",
    "    # fig, axes = plt.subplots(1,2,figsize=(18,5))\n",
    "    for _, (plot, subdf) in zip(axes, df.groupby(\"key\", axis=0)):\n",
    "        fig, ax = plt.subplots()\n",
    "        for line, subsubdf in subdf.groupby(\"label\", axis=0):\n",
    "            vals = subsubdf.mean(axis=0)\n",
    "            err = subsubdf.sem(axis=0)\n",
    "            map_key = (line, plot)\n",
    "            ax.fill_between(\n",
    "                args.lags_show,\n",
    "                vals - err,\n",
    "                vals + err,\n",
    "                alpha=0.2,\n",
    "                color=args.cmap[map_key],\n",
    "            )\n",
    "            ax.plot(\n",
    "                args.lags_show,\n",
    "                vals,\n",
    "                label=f\"{line} ({len(subsubdf)})\",\n",
    "                color=args.cmap[map_key],\n",
    "                ls=args.smap[map_key],\n",
    "                lw=1,\n",
    "            )\n",
    "        for sig in sig_lags:\n",
    "            if sig[0] == plot:\n",
    "                ax.text(\n",
    "                    sig[1],\n",
    "                    0,\n",
    "                    s = \"*\",\n",
    "                    color = sig_lags[sig],\n",
    "                    fontsize = 25\n",
    "                )\n",
    "            # ax.scatter(\n",
    "            #     sig_lags2[f\"{plot}_{line}\"],\n",
    "            #     np.full(len(sig_lags2[f\"{plot}_{line}\"]), 0.001),\n",
    "            #     color=args.cmap[map_key]\n",
    "            # )\n",
    "        # ax.axhline(0, ls=\"dashed\", alpha=0.3, c=\"k\")\n",
    "        ax.axvline(0, ls=\"dashed\", alpha=0.3, c=\"k\")\n",
    "        ax.axvline(-0.1, ls=\"-\", alpha=0.5, c=\"k\")\n",
    "        ax.axvline(-0.5, ls=\"-\", alpha=0.5, c=\"k\")\n",
    "        # ax.set_ylim(0,0.155)\n",
    "        ax.set_ylim(0,0.18)\n",
    "        ax.set_xticks([-2,-1,0,1,2])\n",
    "        # ax.set_yticks([0,0.05,0.1,0.15,0.2])\n",
    "        ax.set_title(f\"{plot}s global average\")\n",
    "        ax.legend(loc=\"upper right\", frameon=False)\n",
    "        ax.set(xlabel=\"Lag (s)\", ylabel=\"Correlation (r)\")\n",
    "        plt.savefig(f\"../prob-improb-{tag}-{plot}.jpeg\")\n",
    "        plt.close()\n",
    "\n",
    "colors = [\"red\", \"blue\"]\n",
    "styles = [\"-\", \"-\", \"-.\", \":\"]\n",
    "cmap = {}\n",
    "smap = {}\n",
    "\n",
    "for label, color in zip(args.unique_labels, colors):\n",
    "    for key, style in zip(args.unique_keys, styles):\n",
    "        cmap[(label, key)] = color\n",
    "        smap[(label, key)] = style\n",
    "\n",
    "args.cmap = cmap\n",
    "args.smap = smap\n",
    "\n",
    "# Plot average encoding plots for whole brain\n",
    "average_encoding(args, df, \"all\", colors[0], colors[1])\n",
    "\n",
    "# Plot average encoding plots for ROIs\n",
    "ROIS = {\n",
    "    # \"preCG\": [\"preCG\"],\n",
    "    # \"postCG\": [\"postCG\"],\n",
    "    # \"SM\": [\"preCG\",\"postCG\"],\n",
    "    # \"TP\": [\"TP\"],\n",
    "    # \"STG\": [\"STG\"],\n",
    "    \"IFG\": [\"BA44\",\"BA45\"],\n",
    "    # \"IFG\": [\"IFG\"],\n",
    "    # \"BA44\": [\"BA44\"],\n",
    "    # \"BA45\": [\"BA45\"],\n",
    "    # \"pMTG\": [\"pMTG\"],\n",
    "    # \"mMTG\": [\"mMTG\"],\n",
    "    # \"AG\": [\"AG\"],\n",
    "}\n",
    "\n",
    "for area_name, area in ROIS.items(): # area\n",
    "    roi_df = df[df.index.isin(sig_df.loc[sig_df.roi_1.isin(area), \"electrode\"].tolist(), level=1)]\n",
    "    average_encoding(args, roi_df, area_name, colors[0], colors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Plot Actual-Pred (Whole Brain and ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average encoding plots\n",
    "def average_encoding(args, df, tag, color1, color2):\n",
    "    sig_lags = get_sigs_perm(args, df, \"actual\", \"pred\", 0.001, color1, color2)\n",
    "    # sig_lags2 = get_sig_lags(args, df, \"actual\", \"pred\", 0.05)\n",
    "    axes = [\"comp\", \"prod\"]\n",
    "    # fig, axes = plt.subplots(1,2,figsize=(18,5))\n",
    "    for _, (plot, subdf) in zip(axes, df.groupby(\"key\", axis=0)):\n",
    "        fig, ax = plt.subplots()\n",
    "        for line, subsubdf in subdf.groupby(\"label\", axis=0):\n",
    "            vals = subsubdf.mean(axis=0)\n",
    "            err = subsubdf.sem(axis=0)\n",
    "            map_key = (line, plot)\n",
    "            ax.fill_between(\n",
    "                args.lags_show,\n",
    "                vals - err,\n",
    "                vals + err,\n",
    "                alpha=0.2,\n",
    "                color=args.cmap[map_key],\n",
    "            )\n",
    "            ax.plot(\n",
    "                args.lags_show,\n",
    "                vals,\n",
    "                label=f\"{line} ({len(subsubdf)})\",\n",
    "                color=args.cmap[map_key],\n",
    "                ls=args.smap[map_key],\n",
    "                lw=1\n",
    "            )\n",
    "        for sig in sig_lags:\n",
    "            if sig[0] == plot:\n",
    "                ax.text(\n",
    "                    sig[1],\n",
    "                    0,\n",
    "                    s = \"*\",\n",
    "                    color = sig_lags[sig],\n",
    "                    fontsize = 25,\n",
    "                )\n",
    "            # ax.scatter(\n",
    "            #     sig_lags2[f\"{plot}_{line}\"],\n",
    "            #     np.full(len(sig_lags2[f\"{plot}_{line}\"]), 0.001),\n",
    "            #     color=args.cmap[map_key]\n",
    "            # )\n",
    "        # ax.set_xticks(args.lag_ticks)\n",
    "        # ax.set_xticklabels(args.lag_tick_labels)\n",
    "        # ax.axhline(0, ls=\"dashed\", alpha=0.3, c=\"k\")\n",
    "        ax.axvline(0, ls=\"dashed\", alpha=0.3, c=\"k\")\n",
    "        ax.axvline(-0.1, ls=\"-\", alpha=0.5, c=\"k\")\n",
    "        ax.axvline(-0.5, ls=\"-\", alpha=0.5, c=\"k\")\n",
    "        # ax.set_ylim(0,0.155)\n",
    "        ax.set_ylim(0,0.18)\n",
    "        ax.set_xticks([-2,-1,0,1,2])\n",
    "        # ax.set_yticks([0,0.05,0.1,0.15,0.2])\n",
    "        ax.set_title(f\"{plot}s global average\")\n",
    "        ax.legend(loc=\"upper right\", frameon=False)\n",
    "        ax.set(xlabel=\"Lag (s)\", ylabel=\"Correlation (r)\")\n",
    "        plt.savefig(f\"../actual-pred-{tag}-{plot}.jpeg\")\n",
    "        plt.close()\n",
    "\n",
    "colors = [\"blue\", \"darkorange\"]\n",
    "styles = [\"-\", \"-\", \"-.\", \":\"]\n",
    "cmap = {}\n",
    "smap = {}\n",
    "\n",
    "for label, color in zip(args.unique_labels, colors):\n",
    "    for key, style in zip(args.unique_keys, styles):\n",
    "        cmap[(label, key)] = color\n",
    "        smap[(label, key)] = style\n",
    "\n",
    "args.cmap = cmap\n",
    "args.smap = smap\n",
    "\n",
    "# Plot average encoding plots for whole brain\n",
    "average_encoding(args, df, \"all\", colors[0], colors[1])\n",
    "\n",
    "# Plot average encoding plots for ROIs\n",
    "ROIS = {\n",
    "    # \"preCG\": [\"preCG\"],\n",
    "    # \"postCG\": [\"postCG\"],\n",
    "    # \"SM\": [\"preCG\",\"postCG\"],\n",
    "    # \"TP\": [\"TP\"],\n",
    "    # \"STG\": [\"STG\"],\n",
    "    # \"IFG\": [\"BA44\",\"BA45\"],\n",
    "    # \"BA44\": [\"BA44\"],\n",
    "    # \"BA45\": [\"BA45\"],\n",
    "    # \"pMTG\": [\"pMTG\"],\n",
    "    # \"mMTG\": [\"mMTG\"],\n",
    "    # \"AG\": [\"AG\"],\n",
    "}\n",
    "\n",
    "for area_name, area in ROIS.items(): # area\n",
    "    roi_df = df[df.index.isin(sig_df.loc[sig_df.roi_1.isin(area), \"electrode\"].tolist(), level=1)]\n",
    "    average_encoding(args, roi_df, area_name, colors[0], colors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Plot Glove-concats (Whole Brain and ROIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average encoding plots\n",
    "def average_encoding(args, df, tag, color1, color2):\n",
    "    # fig, axes = plt.subplots(1, 2, figsize=(18,5))\n",
    "    sig_lags = get_sigs(args, df, \"n\", \"n+4\", 0.001, color1, color2)\n",
    "    sig_lags2 = get_sig_lags(args, df, \"n\", \"n+4\", 0.01)\n",
    "    axes = [\"comp\", \"prod\"]\n",
    "    for _, (plot, subdf) in zip(axes, df.groupby(\"key\", axis=0)):\n",
    "        fig, ax = plt.subplots()\n",
    "        for line, subsubdf in subdf.groupby(\"label\", axis=0):\n",
    "            if line == \"n\" or line == \"n+4\":\n",
    "                pass\n",
    "            else:\n",
    "                continue\n",
    "            vals = subsubdf.mean(axis=0)\n",
    "            err = subsubdf.sem(axis=0)\n",
    "            map_key = (line, plot)\n",
    "            ax.fill_between(\n",
    "                args.lags_show,\n",
    "                vals - err,\n",
    "                vals + err,\n",
    "                alpha=0.2,\n",
    "                color=args.cmap[map_key],\n",
    "            )\n",
    "            ax.plot(\n",
    "                args.lags_show,\n",
    "                vals,\n",
    "                label=f\"{line} ({len(subsubdf)})\",\n",
    "                color=args.cmap[map_key],\n",
    "                ls=args.smap[map_key],\n",
    "                lw=1\n",
    "            )\n",
    "        for sig in sig_lags:\n",
    "            if sig[0] == plot:\n",
    "                ax.text(\n",
    "                    sig[1],\n",
    "                    0,\n",
    "                    s = \"*\",\n",
    "                    color = sig_lags[sig],\n",
    "                    fontsize = 25,\n",
    "                )\n",
    "        ax.scatter(\n",
    "            sig_lags2[f\"{plot}_{line}\"],\n",
    "            np.full(len(sig_lags2[f\"{plot}_{line}\"]), 0.001),\n",
    "            color=args.cmap[map_key]\n",
    "        )\n",
    "        # ax.set_xticks(args.lag_ticks)\n",
    "        # ax.set_xticklabels(args.lag_tick_labels)\n",
    "        ax.set_ylim(0,0.18)\n",
    "        ax.axhline(0, ls=\"dashed\", alpha=0.3, c=\"k\")\n",
    "        ax.axvline(0, ls=\"dashed\", alpha=0.3, c=\"k\")\n",
    "        ax.axvline(-0.1, ls=\"-\", alpha=0.5, c=\"k\")\n",
    "        ax.axvline(-0.5, ls=\"-\", alpha=0.5, c=\"k\")\n",
    "        ax.set_title(f\"{plot}s global average\")\n",
    "        ax.legend(loc=\"upper right\", frameon=False)\n",
    "        ax.set(xlabel=\"Lag (s)\", ylabel=\"Correlation (r)\")\n",
    "        plt.savefig(f\"../concats-{tag}-{plot}.jpeg\")\n",
    "        plt.close()\n",
    "\n",
    "colors = get_con_color(\"viridis\",5)\n",
    "styles = [\"-\", \"-\", \"-\", \"-\",\"-\"]\n",
    "cmap = {}\n",
    "smap = {}\n",
    "\n",
    "for label, color in zip(args.unique_labels, colors):\n",
    "    for key, style in zip(args.unique_keys, styles):\n",
    "        cmap[(label, key)] = color\n",
    "        smap[(label, key)] = style\n",
    "\n",
    "args.cmap = cmap\n",
    "args.smap = smap\n",
    "\n",
    "# Plot average encoding plots for whole brain\n",
    "# average_encoding(args, df, \"all\", colors[0], colors[4])\n",
    "\n",
    "# Plot average encoding plots for ROIs\n",
    "ROIS = {\n",
    "    # \"preCG\": [\"preCG\"],\n",
    "    # \"postCG\": [\"postCG\"],\n",
    "    # \"SM\": [\"preCG\",\"postCG\"],\n",
    "    # \"TP\": [\"TP\"],\n",
    "    # \"STG\": [\"STG\"],\n",
    "    # \"IFG\": [\"BA44\",\"BA45\"],\n",
    "    # \"BA44\": [\"BA44\"],\n",
    "    # \"BA45\": [\"BA45\"],\n",
    "    # \"pMTG\": [\"pMTG\"],\n",
    "    # \"mMTG\": [\"mMTG\"],\n",
    "    # \"AG\": [\"AG\"],\n",
    "    # \"language\": [\"BA44\", \"BA45\", \"AG\"]\n",
    "}\n",
    "\n",
    "for area_name, area in ROIS.items(): # area\n",
    "    roi_df = df[~df.index.isin(sig_df.loc[sig_df.roi_1.isin(area), \"electrode\"].tolist(), level=1)]\n",
    "    average_encoding(args, roi_df, area_name, colors[0], colors[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainmap Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainmap subject plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjects\n",
    "class Args(argparse.Namespace):\n",
    "  main_dir = \"../data/plotting/brainplot/\" # loads coordinate and brain surface files\n",
    "  project = \"tfs\"\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  brain_type = \"ave\" # average brain\n",
    "  hemisphere = \"left\" # only plot left hemisphere\n",
    "  outfile = \"../tfs_sids_%s.svg\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"] # get the encoding default colors\n",
    "color_list = prop_cycle.by_key()[\"color\"]\n",
    "\n",
    "# Set Up Color Split\n",
    "args.colors = color_list\n",
    "\n",
    "for key in args.keys:\n",
    "    sig_df_plot = sig_df[sig_df[f\"gpt2-{key}\"]]\n",
    "    sig_plot = pd.DataFrame({\"electrode\":sig_df_plot.electrode,\"effect\":sig_df_plot.sid})\n",
    "    fig = make_brainmap_cat(args, sig_plot, args.outfile % key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainmap ROI plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_df_areas = sig_df[sig_df.roi_1.isin([\"IFG\",\"STG\",\"TP\",\"preCG\",\"postCG\",\"AG\"])]\n",
    "\n",
    "# Subjects\n",
    "class Args(argparse.Namespace):\n",
    "  main_dir = \"../data/plotting/brainplot/\" # loads coordinate and brain surface files\n",
    "  project = \"tfs\"\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  brain_type = \"ave\" # average brain\n",
    "  hemisphere = \"left\" # only plot left hemisphere\n",
    "  outfile = \"../tfs_areas_%s.svg\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "color_list = px.colors.qualitative.Prism # 10 colors\n",
    "color_list = [\"rgb(55,126,184)\",\"rgb(255,127,0)\",\"rgb(77,175,74)\",\"rgb(152,78,163)\"]\n",
    "args.colors = color_list\n",
    "\n",
    "for key in args.keys:\n",
    "  sig_df_plot = sig_df_areas[sig_df_areas[f\"gpt2-{key}\"]]\n",
    "  sig_plot = pd.DataFrame({\"electrode\":sig_df_plot.electrode,\"effect\":sig_df_plot.roi_1})\n",
    "  fig = make_brainmap_cat(args, sig_plot, args.outfile % key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting effect Prob-improb (area difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_df(label):  # get partial df\n",
    "    idx = pd.IndexSlice\n",
    "    part_df = chosen_df.loc[idx[label, :, :, :], :].copy()\n",
    "    part_df.index = part_df.index.droplevel(\"label\")\n",
    "    part_df_idx = part_df.index.get_level_values(\"electrode\").tolist()\n",
    "    part_df = part_df.sort_index()\n",
    "    return part_df, part_df_idx\n",
    "\n",
    "chosen_lags = np.arange(-500,-99,25) # before onset\n",
    "# chosen_lags = np.arange(200,601,25) # after onset\n",
    "lags_show = np.arange(-10000,10001,25)\n",
    "chosen_lags = [idx for (idx, lag) in enumerate(lags_show) if lag in chosen_lags]\n",
    "chosen_df = df.loc[:,chosen_lags]\n",
    "x_vals = [lags_show[lag] / 1000 for lag in chosen_lags]\n",
    "\n",
    "# Get Effect\n",
    "# chosen_df[\"area\"] = np.trapz(chosen_df, x=x_vals, axis=1) # get area\n",
    "chosen_df[\"area\"] = chosen_df.loc[:,chosen_lags].sum(axis=1) # get sum\n",
    "df1, _ = get_part_df(\"prob\") # get first encoding\n",
    "df2, _ = get_part_df(\"improb\") # get second encoding\n",
    "df1[\"area2\"] = df2[\"area\"]\n",
    "df1.loc[:, \"effect\"] = df1[\"area\"] - df1[\"area2\"] # diff\n",
    "# df1.loc[:, \"effect\"] = (df1[\"area\"] - df1[\"area2\"]) / df1[[\"area\", \"area2\"]].max(axis=1) # diff\n",
    "# df1.loc[:, \"effect\"] = (df1[\"area\"] - df1[\"area2\"]) / (df1[\"area\"] + df1[\"area2\"]) # norm diff\n",
    "\n",
    "# sig test\n",
    "threshold = 0.01\n",
    "for row, _ in df1.iterrows():\n",
    "    r = ttest_ind(df1.loc[row,chosen_lags], df2.loc[row,chosen_lags], alternative=\"two-sided\")\n",
    "    df1.loc[row, \"sig\"] = r[1]\n",
    "\n",
    "# # fdr\n",
    "idx = pd.IndexSlice\n",
    "df1.loc[idx[:, \"comp\", :], \"sig\"] = fdr(df1.loc[idx[:, \"comp\", :], \"sig\"])\n",
    "df1.loc[idx[:, \"prod\", :], \"sig\"] = fdr(df1.loc[idx[:, \"prod\", :], \"sig\"])\n",
    "\n",
    "print(sum(df1.sig > threshold))\n",
    "df1.loc[df1.sig > threshold, \"effect\"] = -1000\n",
    "# df1 = df1[df1.sig <= threshold]\n",
    "\n",
    "chosen_df = df1\n",
    "chosen_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting effect actual - pred (area difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_df(label):  # get partial df\n",
    "    idx = pd.IndexSlice\n",
    "    part_df = chosen_df.loc[idx[label, :, :, :], :].copy()\n",
    "    part_df.index = part_df.index.droplevel(\"label\")\n",
    "    part_df_idx = part_df.index.get_level_values(\"electrode\").tolist()\n",
    "    part_df = part_df.sort_index()\n",
    "    return part_df, part_df_idx\n",
    "\n",
    "chosen_lags = np.arange(-500,-99,25) # before onset\n",
    "# chosen_lags = np.arange(200,601,25) # after onset\n",
    "lags_show = np.arange(-10000,10001,25)\n",
    "chosen_lags = [idx for (idx, lag) in enumerate(lags_show) if lag in chosen_lags]\n",
    "chosen_df = df.loc[:,chosen_lags]\n",
    "x_vals = [lags_show[lag] / 1000 for lag in chosen_lags]\n",
    "\n",
    "# Get Effect\n",
    "# chosen_df[\"area\"] = np.trapz(chosen_df, x=x_vals, axis=1) # get area\n",
    "chosen_df[\"area\"] = chosen_df.loc[:,chosen_lags].sum(axis=1) # get sum\n",
    "df1, _ = get_part_df(\"actual\") # get first encoding\n",
    "df2, _ = get_part_df(\"pred\") # get second encoding\n",
    "df1[\"area2\"] = df2[\"area\"]\n",
    "df1.loc[:, \"effect\"] = df1[\"area\"] - df1[\"area2\"] # diff\n",
    "# df1.loc[:, \"effect\"] = (df1[\"area\"] - df1[\"area2\"]) / df1[[\"area\", \"area2\"]].max(axis=1) # diff\n",
    "# df1.loc[:, \"effect\"] = (df1[\"area\"] - df1[\"area2\"]) / (df1[\"area\"] + df1[\"area2\"]) # norm diff\n",
    "\n",
    "# sig test\n",
    "threshold = 0.01\n",
    "for row, _ in df1.iterrows():\n",
    "    r = ttest_ind(df1.loc[row,chosen_lags], df2.loc[row,chosen_lags], alternative=\"two-sided\")\n",
    "    df1.loc[row, \"sig\"] = r[1]\n",
    "\n",
    "# fdr\n",
    "idx = pd.IndexSlice\n",
    "df1.loc[idx[:, \"comp\", :], \"sig\"] = fdr(df1.loc[idx[:, \"comp\", :], \"sig\"])\n",
    "df1.loc[idx[:, \"prod\", :], \"sig\"] = fdr(df1.loc[idx[:, \"prod\", :], \"sig\"])\n",
    "\n",
    "print(sum(df1.sig > threshold))\n",
    "df1.loc[df1.sig > threshold, \"effect\"] = -1000\n",
    "# df1 = df1[df1.sig <= threshold]\n",
    "\n",
    "chosen_df = df1\n",
    "chosen_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brainmap plots for area difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  main_dir = \"../data/plotting/brainplot/\" # loads coordinate and brain surface files\n",
    "  project = \"tfs\"\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  # keys = [\"prod\"] # comprehension and/or production\n",
    "  brain_type = \"ave\" # average brain\n",
    "  hemisphere = \"left\" # only plot left hemisphere\n",
    "  outfile = \"../tfs-diff_%s.svg\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Customize Your Color Split Here\n",
    "grad_1 = 300\n",
    "grad_2 = 800\n",
    "insig = \"#ffffff\"\n",
    "insig = \"#ebebeb\"\n",
    "zero_bar = Colorbar(title=\"insig\",colorscale=[[0,insig],[1,insig]],bar_min=-1000,bar_max=-1000)\n",
    "\n",
    "# Red & Blue whisper notebook\n",
    "# pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, \"rgb(255,248,240)\"], [1, \"rgb(255,0,0)\"]],bar_min=0.1,bar_max=1)\n",
    "# neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, \"rgb(0,0,255)\"], [1, \"rgb(240,248,255)\"]],bar_min=-1,bar_max=-0.1)\n",
    "\n",
    "# Red & Blue whisper\n",
    "# pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, \"#ffa07a\"], [1, \"#ff0000\"]],bar_min=0.1,bar_max=1)\n",
    "# neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, \"#0000ff\"], [1, \"#87ceff\"]],bar_min=-1,bar_max=-0.1)\n",
    "\n",
    "# Red & Blue gradient\n",
    "# pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, col.to_hex(red_list[grad_1])], [1, col.to_hex(red_list[grad_2])]],bar_min=0.1,bar_max=1)\n",
    "# neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, col.to_hex(blu_list[grad_2])], [1, col.to_hex(blu_list[grad_1])]],bar_min=-1,bar_max=-0.1)\n",
    "\n",
    "# Blue & Orange whisper notebook\n",
    "# pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, \"rgb(240,248,255)\"], [1, \"rgb(0,0,255)\"]],bar_min=0,bar_max=1)\n",
    "# neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, \"rgb(255, 127, 14)\"], [1, \"rgb(255,248,240)\"]],bar_min=-1,bar_max=0)\n",
    "\n",
    "# Blue & Orange gradient\n",
    "pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, col.to_hex(blu_list[grad_1])], [1, col.to_hex(blu_list[grad_2])]],bar_min=0.1,bar_max=1)\n",
    "neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, col.to_hex(ora_list[grad_2])], [1, col.to_hex(ora_list[grad_1])]],bar_min=-1,bar_max=-0.1)\n",
    "\n",
    "# Green & Purple\n",
    "# pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, \"rgb(135,206,1)\"],[1, \"rgb(0,102,0)\"]],bar_min=0,bar_max=1)\n",
    "# neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, \"rgb(128,0,128)\"],[1, \"rgb(238,130,238)\"]],bar_min=-1,bar_max=0)\n",
    "args.color_split = [zero_bar,-100,neg_bar,0,pos_bar]\n",
    "# args.color_split = [neg_bar,0,pos_bar]\n",
    "\n",
    "for key in args.keys: # comp/prod\n",
    "    df_plot = chosen_df.loc[chosen_df.key == key, (\"electrode\", \"effect\")]\n",
    "    fig = make_brainmap(args, df_plot, args.outfile % key) # plot png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting effect for Glove-concats (area difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_df(label):  # get partial df\n",
    "    idx = pd.IndexSlice\n",
    "    part_df = chosen_df.loc[idx[label, :, :, :], :].copy()\n",
    "    part_df.index = part_df.index.droplevel(\"label\")\n",
    "    part_df_idx = part_df.index.get_level_values(\"electrode\").tolist()\n",
    "    part_df = part_df.sort_index()\n",
    "    return part_df, part_df_idx\n",
    "\n",
    "chosen_lags = np.arange(-500,-99,25) # before onset\n",
    "# chosen_lags = np.arange(100,501,25) # after onset\n",
    "lags_show = np.arange(-10000,10001,25)\n",
    "chosen_lags = [idx for (idx, lag) in enumerate(lags_show) if lag in chosen_lags]\n",
    "chosen_df = df.loc[:,chosen_lags]\n",
    "x_vals = [lags_show[lag] / 1000 for lag in chosen_lags]\n",
    "\n",
    "# Get Effect\n",
    "# chosen_df[\"area\"] = np.trapz(chosen_df, x=x_vals, axis=1) # get area\n",
    "chosen_df[\"area\"] = chosen_df.loc[:,chosen_lags].sum(axis=1) # get sum\n",
    "df1, _ = get_part_df(\"n+4\") # get first encoding\n",
    "df2, _ = get_part_df(\"n+3\") # get second encoding\n",
    "df3, _ = get_part_df(\"n+2\") # get second encoding\n",
    "df4, _ = get_part_df(\"n+1\") # get second encoding\n",
    "df5, _ = get_part_df(\"n\") # get second encoding\n",
    "df1[\"area2\"] = df2[\"area\"]\n",
    "df1[\"area3\"] = df3[\"area\"]\n",
    "df1[\"area4\"] = df4[\"area\"]\n",
    "df1[\"area5\"] = df5[\"area\"]\n",
    "# df1.loc[:, \"effect1\"] = (df1[\"area\"] - df1[\"area2\"]) / (df1[\"area\"] + df1[\"area2\"])\n",
    "# df1.loc[:, \"effect2\"] = (df1[\"area2\"] - df1[\"area3\"]) / (df1[\"area2\"] + df1[\"area3\"])\n",
    "# df1.loc[:, \"effect3\"] = (df1[\"area3\"] - df1[\"area4\"]) / (df1[\"area3\"] + df1[\"area4\"])\n",
    "# df1.loc[:, \"effect4\"] = (df1[\"area4\"] - df1[\"area5\"]) / (df1[\"area4\"] + df1[\"area5\"])\n",
    "# df1.loc[:, \"effect\"] = df1.effect1 + df1.effect2 + df1.effect3 + df1.effect4\n",
    "df1.loc[:, \"effect\"] = (df1[\"area\"] - df1[\"area5\"]) / df1[[\"area\", \"area5\"]].max(axis=1) # diff\n",
    "# df1.loc[:, \"effect\"] = df1[\"area\"] - df1[\"area5\"] # diff\n",
    "\n",
    "# sig test\n",
    "threshold = 0.01\n",
    "for row, _ in df1.iterrows():\n",
    "    r = ttest_ind(df1.loc[row,chosen_lags], df5.loc[row,chosen_lags], alternative=\"two-sided\")\n",
    "    df1.loc[row, \"sig\"] = r[1]\n",
    "\n",
    "# fdr\n",
    "idx = pd.IndexSlice\n",
    "df1.loc[idx[:, \"comp\", :], \"sig\"] = fdr(df1.loc[idx[:, \"comp\", :], \"sig\"])\n",
    "df1.loc[idx[:, \"prod\", :], \"sig\"] = fdr(df1.loc[idx[:, \"prod\", :], \"sig\"])\n",
    "\n",
    "print(sum(df1.sig > threshold))\n",
    "# df1.loc[df1.sig > threshold, \"effect\"] = -1000\n",
    "df1 = df1[df1.sig <= threshold]\n",
    "\n",
    "chosen_df = df1\n",
    "chosen_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  main_dir = \"../data/plotting/brainplot/\" # loads coordinate and brain surface files\n",
    "  project = \"tfs\"\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  brain_type = \"ave\" # average brain\n",
    "  hemisphere = \"left\" # only plot left hemisphere\n",
    "  outfile = \"../tfs-diff_%s.svg\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Customize Your Color Split Here\n",
    "grad_1 = 400\n",
    "grad_2 = 900\n",
    "insig = \"#ffffff\"\n",
    "insig = \"#ebebeb\"\n",
    "zero_bar = Colorbar(title=\"insig\",colorscale=[[0,insig],[1,insig]],bar_min=-1000,bar_max=-1000)\n",
    "\n",
    "# Green & Purple whisper notebook\n",
    "# pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, \"rgb(135,206,1)\"],[1, \"rgb(0,102,0)\"]],bar_min=0.05,bar_max=0.5)\n",
    "# neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, \"rgb(128,0,128)\"],[1, \"rgb(238,130,238)\"]],bar_min=-0.5,bar_max=-0.05)\n",
    "\n",
    "# Green & Purple whisper\n",
    "# pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, \"#00fa9a\"],[1, \"#006400\"]],bar_min=0.1,bar_max=1)\n",
    "# neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, \"#800080\"],[1, \"#ee82ee\"]],bar_min=-1,bar_max=0.1)\n",
    "\n",
    "# Green & Purple gradient\n",
    "pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, col.to_hex(gre_list[grad_1])],[1, col.to_hex(gre_list[grad_2])]],bar_min=0.05,bar_max=0.5)\n",
    "neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, col.to_hex(pur_list[grad_2])],[1, col.to_hex(pur_list[grad_1])]],bar_min=-0.5,bar_max=-0.05)\n",
    "# args.color_split = [zero_bar,-100,neg_bar,0,pos_bar]\n",
    "args.color_split = [neg_bar,0,pos_bar]\n",
    "\n",
    "for key in args.keys: # comp/prod\n",
    "    df_plot = chosen_df.loc[chosen_df.key == key, (\"electrode\", \"effect\")]\n",
    "    fig = make_brainmap(args, df_plot, args.outfile % key) # plot png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_gap_df = load_pickle(\"../data/plotting/paper-prob-improb/datums/df.pkl\")\n",
    "# word_gap_df_mid = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_mid.pkl\")\n",
    "word_gap_df_top = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_top_a.pkl\")\n",
    "word_gap_df_bot = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_bot_a.pkl\")\n",
    "# word_gap_df_top = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_top_na.pkl\")\n",
    "# word_gap_df_bot = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_bot_na.pkl\")\n",
    "# word_gap_df_top = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_top.pkl\")\n",
    "# word_gap_df_bot = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_bot.pkl\")\n",
    "word_gap_df_top[\"pred\"] = \"top 30%\"\n",
    "# word_gap_df_mid[\"pred\"] = \"mid 30%\"\n",
    "word_gap_df_bot[\"pred\"] = \"bot 30%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_top = word_gap_df_top[(word_gap_df_top.word_gap >= 0) & (word_gap_df_top.word_gap <= 300)]\n",
    "gap_bot = word_gap_df_bot[(word_gap_df_bot.word_gap >= 0) & (word_gap_df_bot.word_gap <= 300)]\n",
    "\n",
    "speaker_dict = {\n",
    "    625: \"Speaker 1\",\n",
    "    676: \"Speaker 2\",\n",
    "    7170: \"Speaker 3\",\n",
    "    798: \"Speaker 4\",\n",
    "}\n",
    "\n",
    "means = []\n",
    "sems = []\n",
    "speakers = []\n",
    "gap_type = []\n",
    "\n",
    "for sid in speaker_dict:\n",
    "    gap_plot = gap_top[(gap_top.sid == sid) & (gap_top.speaker == \"Speaker1\")]\n",
    "    means.append(gap_plot.word_gap.mean())\n",
    "    sems.append(gap_plot.word_gap.sem())\n",
    "    speakers.append(speaker_dict[sid])\n",
    "    gap_type.append(\"probable\")\n",
    "gap_plot = gap_top[gap_top.speaker != \"Speaker1\"]\n",
    "means.append(gap_plot.word_gap.mean())\n",
    "sems.append(gap_plot.word_gap.sem())\n",
    "speakers.append(\"Other\")\n",
    "gap_type.append(\"probable\")\n",
    "\n",
    "for sid in speaker_dict:\n",
    "    gap_plot = gap_bot[(gap_bot.sid == sid) & (gap_bot.speaker == \"Speaker1\")]\n",
    "    means.append(gap_plot.word_gap.mean())\n",
    "    sems.append(gap_plot.word_gap.sem())\n",
    "    speakers.append(speaker_dict[sid])\n",
    "    gap_type.append(\"improbable\")\n",
    "gap_plot = gap_bot[gap_bot.speaker != \"Speaker1\"]\n",
    "means.append(gap_plot.word_gap.mean())\n",
    "sems.append(gap_plot.word_gap.sem())\n",
    "speakers.append(\"Other\")\n",
    "gap_type.append(\"improbable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_top = word_gap_df_top[word_gap_df_top.word_len >= 0]\n",
    "gap_bot = word_gap_df_bot[word_gap_df_bot.word_len >= 0]\n",
    "\n",
    "speaker_dict = {\n",
    "    625: \"Speaker 1\",\n",
    "    676: \"Speaker 2\",\n",
    "    7170: \"Speaker 3\",\n",
    "    798: \"Speaker 4\",\n",
    "}\n",
    "\n",
    "means = []\n",
    "sems = []\n",
    "speakers = []\n",
    "gap_type = []\n",
    "\n",
    "for sid in speaker_dict:\n",
    "    gap_plot = gap_top[(gap_top.sid == sid) & (gap_top.speaker == \"Speaker1\")]\n",
    "    means.append(gap_plot.word_len.mean())\n",
    "    sems.append(gap_plot.word_len.sem())\n",
    "    speakers.append(speaker_dict[sid])\n",
    "    gap_type.append(\"probable\")\n",
    "gap_plot = gap_top[gap_top.speaker != \"Speaker1\"]\n",
    "means.append(gap_plot.word_len.mean())\n",
    "sems.append(gap_plot.word_len.sem())\n",
    "speakers.append(\"zOther\")\n",
    "gap_type.append(\"probable\")\n",
    "\n",
    "for sid in speaker_dict:\n",
    "    gap_plot = gap_bot[(gap_bot.sid == sid) & (gap_bot.speaker == \"Speaker1\")]\n",
    "    means.append(gap_plot.word_len.mean())\n",
    "    sems.append(gap_plot.word_len.sem())\n",
    "    speakers.append(speaker_dict[sid])\n",
    "    gap_type.append(\"improbable\")\n",
    "gap_plot = gap_bot[gap_bot.speaker != \"Speaker1\"]\n",
    "means.append(gap_plot.word_len.mean())\n",
    "sems.append(gap_plot.word_len.sem())\n",
    "speakers.append(\"zOther\")\n",
    "gap_type.append(\"improbable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"mean\": means,\n",
    "        \"sem\": sems,\n",
    "        \"Speakers\": speakers,\n",
    "        \"word_type\": gap_type,\n",
    "    }\n",
    ")\n",
    "dfp = results_df.pivot(\n",
    "    index=\"Speakers\", columns=\"word_type\", values=\"mean\"\n",
    ")\n",
    "yerr = results_df.pivot(index=\"Speakers\", columns=\"word_type\", values=\"sem\")\n",
    "colors = [\"blue\",\"red\"]\n",
    "dfp.plot(\n",
    "    kind=\"bar\",\n",
    "    yerr=yerr,\n",
    "    rot=0,\n",
    "    color=colors,\n",
    "    error_kw=dict(ecolor=\"black\", elinewidth=1, capsize=1),\n",
    ")\n",
    "\n",
    "plt.savefig(\"../whisker.jpeg\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gap = word_gap_df[(word_gap_df.word_gap >= 0) & (word_gap_df.word_gap <= 300)]\n",
    "# gap_top = word_gap_df_top[(word_gap_df_top.word_gap >= 0) & (word_gap_df_top.word_gap <= 300)]\n",
    "# gap_mid = word_gap_df_mid[(word_gap_df_mid.word_gap >= 0) & (word_gap_df_mid.word_gap <= 300)]\n",
    "# gap_bot = word_gap_df_bot[(word_gap_df_bot.word_gap >= 0) & (word_gap_df_bot.word_gap <= 300)]\n",
    "\n",
    "# gap_top_prod = gap_top[gap_top.speaker == \"Speaker1\"]\n",
    "# gap_top_comp = gap_top[gap_top.speaker != \"Speaker1\"]\n",
    "# gap_mid_prod = gap_mid[gap_mid.speaker == \"Speaker1\"]\n",
    "# gap_mid_comp = gap_mid[gap_mid.speaker != \"Speaker1\"]\n",
    "# gap_bot_prod = gap_bot[gap_bot.speaker == \"Speaker1\"]\n",
    "# gap_bot_comp = gap_bot[gap_bot.speaker != \"Speaker1\"]\n",
    "\n",
    "# gap_prod = pd.concat((gap_top_prod, gap_mid_prod, gap_bot_prod))\n",
    "# gap_comp = pd.concat((gap_top_comp, gap_mid_comp, gap_bot_comp))\n",
    "# gap_prod.reset_index(drop=True, inplace=True)\n",
    "# gap_comp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "# cols = {\"top 30%\":\"r\", \"bot 30%\" : \"b\", \"mid 30%\": \"orange\"}\n",
    "# sns.boxplot(x=\"pred\",y=\"word_gap_log\",data=gap_comp, ax=axes[0], showfliers = False, palette=cols, linewidth=2)\n",
    "# sns.boxplot(x=\"pred\",y=\"word_gap_log\",data=gap_prod, ax=axes[1], showfliers = False, palette=cols, linewidth=2)\n",
    "# plt.savefig(f\"../whisker_word_gap_log.jpeg\")\n",
    "\n",
    "# cols = {\"top 30%\":\"r\", \"bot 30%\" : \"b\", \"mid 30%\": \"orange\"}\n",
    "# sns.displot(data=gap_comp, x=\"word_gap\", hue=\"pred\",kind=\"kde\", fill=True)\n",
    "# # sns.displot(data=gap_prod, x=\"word_gap\", hue=\"pred\", ax=axes[1])\n",
    "# plt.savefig(f\"../density.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_top_prod.true_pred_prob.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligned Num-aligned exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_a = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_top_a.pkl\")\n",
    "df_bot_a = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_bot_a.pkl\")\n",
    "df_top_na = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_top_na.pkl\")\n",
    "df_bot_na = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_bot_na.pkl\")\n",
    "df_top = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_top.pkl\")\n",
    "df_bot = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_bot.pkl\")\n",
    "\n",
    "df_top_a[\"pred\"] = \"aligned\"\n",
    "df_bot_a[\"pred\"] = \"aligned\"\n",
    "df_top_na[\"pred\"] = \"num-aligned\"\n",
    "df_bot_na[\"pred\"] = \"num-aligned\"\n",
    "df_top[\"pred\"] = \"original\"\n",
    "df_bot[\"pred\"] = \"original\"\n",
    "\n",
    "df_top_plot = pd.concat((df_top_na,df_top_a,df_top))\n",
    "df_bot_plot = pd.concat((df_bot_na,df_bot_a,df_bot))\n",
    "df_top_plot.drop_duplicates(subset=[\"sid\",\"adjusted_onset\",\"adjusted_offset\",\"word\"],keep=\"first\",inplace=True)\n",
    "df_bot_plot.drop_duplicates(subset=[\"sid\",\"adjusted_onset\",\"adjusted_offset\",\"word\"],keep=\"first\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_types = [\"original\", \"num-aligned\", \"aligned\"]\n",
    "\n",
    "for pred_type in pred_types:\n",
    "    df_top_pred = df_top_plot[df_top_plot.pred == pred_type]\n",
    "    df_top_pred.groupby(df_top_pred.word).size().sort_values(ascending=False).to_csv(f\"../data/plotting/paper-prob-improb/datums/top-{pred_type}.csv\")\n",
    "    df_bot_pred = df_bot_plot[df_bot_plot.pred == pred_type]\n",
    "    df_bot_pred.groupby(df_bot_pred.word).size().sort_values(ascending=False).to_csv(f\"../data/plotting/paper-prob-improb/datums/bot-{pred_type}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in df_top_plot.sid.unique():\n",
    "    df_top_plot_comp = df_top_plot[(df_top_plot.sid == sid) & (df_top_plot.speaker != \"Speaker1\")]\n",
    "    df_top_plot_prod = df_top_plot[(df_top_plot.sid == sid) & (df_top_plot.speaker == \"Speaker1\")]\n",
    "    df_bot_plot_comp = df_bot_plot[(df_bot_plot.sid == sid) & (df_bot_plot.speaker != \"Speaker1\")]\n",
    "    df_bot_plot_prod = df_bot_plot[(df_bot_plot.sid == sid) & (df_bot_plot.speaker == \"Speaker1\")]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    axes[0].set(yscale=\"log\")\n",
    "    axes[1].set(yscale=\"log\")\n",
    "    sns.scatterplot(data=df_top_plot_comp,x=df_top_plot_comp[\"adjusted_onset\"],y=df_top_plot_comp[\"true_pred_rank\"],hue=df_top_plot_comp[\"pred\"], linewidth=0,s=5, markers=[\"o\"],ax=axes[0])\n",
    "    sns.scatterplot(data=df_top_plot_prod,x=df_top_plot_prod[\"adjusted_onset\"],y=df_top_plot_prod[\"true_pred_rank\"],hue=df_top_plot_prod[\"pred\"], linewidth=0,s=5, markers=[\"o\"],ax=axes[1])\n",
    "    plt.savefig(f\"../{sid}-top.jpeg\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    axes[0].set(yscale=\"log\")\n",
    "    axes[1].set(yscale=\"log\")\n",
    "    sns.scatterplot(data=df_bot_plot_comp,x=df_bot_plot_comp[\"adjusted_onset\"],y=df_bot_plot_comp[\"true_pred_rank\"],hue=df_bot_plot_comp[\"pred\"], linewidth=0,s=5, markers=[\"o\"],ax=axes[0])\n",
    "    sns.scatterplot(data=df_bot_plot_prod,x=df_bot_plot_prod[\"adjusted_onset\"],y=df_bot_plot_prod[\"true_pred_rank\"],hue=df_bot_plot_prod[\"pred\"], linewidth=0,s=5, markers=[\"o\"],ax=axes[1])\n",
    "    plt.savefig(f\"../{sid}-bot.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_pred.pkl\")\n",
    "df_pred_mid = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_pred_mid.pkl\")\n",
    "df_pred_top = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_pred_top.pkl\")\n",
    "df_pred_bot = load_pickle(\"../data/plotting/paper-prob-improb/datums/df_pred_bot.pkl\")\n",
    "df_pred_top[\"pred\"] = \"top 30%\"\n",
    "df_pred_mid[\"pred\"] = \"mid 30%\"\n",
    "df_pred_bot[\"pred\"] = \"bot 30%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_preds(df):\n",
    "    for i in np.arange(0,20):\n",
    "        df[f\"true_pred_prob_{i}\"] = df.true_pred_prob.apply(lambda x: x[i] if len(x) > i else None)\n",
    "        df[f\"true_pred_rank_{i}\"] = df.true_pred_rank.apply(lambda x: x[i] if len(x) > i else None)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_pred = separate_preds(df_pred)\n",
    "df_pred_top = separate_preds(df_pred_top)\n",
    "df_pred_bot = separate_preds(df_pred_bot)\n",
    "df_pred_mid = separate_preds(df_pred_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "df_dict = {\n",
    "    \"all\": df_pred,\n",
    "    \"top\": df_pred_top,\n",
    "    \"mid\": df_pred_mid,\n",
    "    \"bot\": df_pred_bot,\n",
    "}\n",
    "\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"9467bd\"]\n",
    "\n",
    "for idx, df_name in enumerate(df_dict):\n",
    "    df_plot = df_dict[df_name]\n",
    "    df_comp = df_plot[df_plot.speaker != \"Speaker1\"]\n",
    "    df_prod = df_plot[df_plot.speaker == \"Speaker1\"]\n",
    "    # comp_median = df_comp.filter(like=\"true_pred_prob_\", axis=1).median(skipna=True)\n",
    "    # prod_median = df_prod.filter(like=\"true_pred_prob_\", axis=1).median(skipna=True)\n",
    "    comp_mean = df_comp.filter(like=\"true_pred_prob_\", axis=1).mean(skipna=True)\n",
    "    prod_mean = df_prod.filter(like=\"true_pred_prob_\", axis=1).mean(skipna=True)\n",
    "    comp_sem = df_comp.filter(like=\"true_pred_prob_\", axis=1).sem(skipna=True)\n",
    "    prod_sem = df_prod.filter(like=\"true_pred_prob_\", axis=1).sem(skipna=True)\n",
    "    axes[0].plot(\n",
    "        np.arange(0,20),\n",
    "        comp_mean,\n",
    "        label = df_name,\n",
    "        marker = \"o\",\n",
    "        color = colors[idx]\n",
    "    )\n",
    "    axes[0].fill_between(\n",
    "        np.arange(0,20),\n",
    "        comp_mean - comp_sem,\n",
    "        comp_mean + comp_sem,\n",
    "        alpha = 0.2,\n",
    "        color = colors[idx]\n",
    "    )\n",
    "    axes[1].plot(\n",
    "        np.arange(0,20),\n",
    "        prod_mean,\n",
    "        label = df_name,\n",
    "        marker = \"o\",\n",
    "        color = colors[idx]\n",
    "    )\n",
    "    axes[1].fill_between(\n",
    "        np.arange(0,20),\n",
    "        prod_mean - prod_sem,\n",
    "        prod_mean + prod_sem,\n",
    "        alpha = 0.2,\n",
    "        color = colors[idx]\n",
    "    )\n",
    "axes[0].legend(loc=\"upper right\", frameon=False)\n",
    "axes[1].legend(loc=\"upper right\", frameon=False)\n",
    "plt.savefig(f\"../pred.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "df_dict = {\n",
    "    \"all\": df_pred,\n",
    "    \"top\": df_pred_top,\n",
    "    \"mid\": df_pred_mid,\n",
    "    \"bot\": df_pred_bot,\n",
    "}\n",
    "\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"9467bd\"]\n",
    "\n",
    "\n",
    "for idx, df_name in enumerate(df_dict):\n",
    "    df_plot = df_dict[df_name]\n",
    "    df_comp = df_plot[df_plot.speaker != \"Speaker1\"]\n",
    "    df_prod = df_plot[df_plot.speaker == \"Speaker1\"]\n",
    "    comp_median = df_comp.filter(like=\"true_pred_rank_\", axis=1).median(skipna=True)\n",
    "    prod_median = df_prod.filter(like=\"true_pred_rank_\", axis=1).median(skipna=True)\n",
    "    comp_mean = df_comp.filter(like=\"true_pred_rank_\", axis=1).mean(skipna=True)\n",
    "    prod_mean = df_prod.filter(like=\"true_pred_rank_\", axis=1).mean(skipna=True)\n",
    "    comp_sem = df_comp.filter(like=\"true_pred_rank_\", axis=1).sem(skipna=True)\n",
    "    prod_sem = df_prod.filter(like=\"true_pred_rank_\", axis=1).sem(skipna=True)\n",
    "    axes[0].plot(\n",
    "        np.arange(0,20),\n",
    "        comp_median,\n",
    "        label = df_name,\n",
    "        marker = \"o\",\n",
    "        color = colors[idx]\n",
    "    )\n",
    "    # axes[0].fill_between(\n",
    "    #     np.arange(0,20),\n",
    "    #     comp_mean - comp_sem,\n",
    "    #     comp_mean + comp_sem,\n",
    "    #     alpha = 0.2,\n",
    "    #     color = colors[idx]\n",
    "    # )\n",
    "    axes[1].plot(\n",
    "        np.arange(0,20),\n",
    "        prod_median,\n",
    "        label = df_name,\n",
    "        marker = \"o\",\n",
    "        color = colors[idx]\n",
    "    )\n",
    "    # axes[1].fill_between(\n",
    "    #     np.arange(0,20),\n",
    "    #     prod_mean - prod_sem,\n",
    "    #     prod_mean + prod_sem,\n",
    "    #     alpha=0.2,\n",
    "    #     color = colors[idx]\n",
    "    # )\n",
    "axes[0].legend(loc=\"lower right\", frameon=False)\n",
    "axes[1].legend(loc=\"lower right\", frameon=False)\n",
    "plt.savefig(f\"../rank.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "df_dict = {\n",
    "    \"all\": df_pred,\n",
    "    \"top\": df_pred_top,\n",
    "    \"mid\": df_pred_mid,\n",
    "    \"bot\": df_pred_bot,\n",
    "}\n",
    "\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"9467bd\"]\n",
    "rank_filter = 5\n",
    "\n",
    "for idx, df_name in enumerate(df_dict):\n",
    "    df_plot = df_dict[df_name]\n",
    "    df_comp = df_plot[df_plot.speaker != \"Speaker1\"]\n",
    "    df_prod = df_plot[df_plot.speaker == \"Speaker1\"]\n",
    "    comp_mean = df_comp.filter(like=\"true_pred_rank_\", axis=1)\n",
    "    prod_mean = df_prod.filter(like=\"true_pred_rank_\", axis=1)\n",
    "    comp_mean = comp_mean[comp_mean <= rank_filter].count() / len(comp_mean)\n",
    "    prod_mean = prod_mean[prod_mean <= rank_filter].count() / len(prod_mean)\n",
    "    axes[0].plot(\n",
    "        np.arange(0,20),\n",
    "        comp_mean,\n",
    "        label = df_name,\n",
    "        marker = \"o\",\n",
    "        color = colors[idx]\n",
    "    )\n",
    "    axes[1].plot(\n",
    "        np.arange(0,20),\n",
    "        prod_mean,\n",
    "        label = df_name,\n",
    "        marker = \"o\",\n",
    "        color = colors[idx]\n",
    "    )\n",
    "axes[0].legend(loc=\"upper right\", frameon=False)\n",
    "axes[1].legend(loc=\"upper right\", frameon=False)\n",
    "plt.savefig(f\"../accuracy.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
