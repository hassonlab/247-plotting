{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as col\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from scipy.stats import ttest_1samp, ttest_ind, ttest_rel, permutation_test\n",
    "from statsmodels.stats import multitest\n",
    "\n",
    "from tfsemb_class import tsne, save_pickle, add_speech\n",
    "from tfsplt_encoding import get_cmap_smap, get_sid, aggregate_data, organize_data\n",
    "from tfsplt_utils import read_folder, load_pickle, get_con_color, get_cat_color\n",
    "from tfsplt_brainmap import get_sigelecs, Colorbar, make_brainmap\n",
    "from tfsplt_brainmap_cat import make_brainmap_cat\n",
    "\n",
    "plt.style.use('/scratch/gpfs/ln1144/247-plotting/scripts/paper.mlpstyle')\n",
    "# plt.style.use('../data/plotting/paper-prob-improb/paper.mlpstyle')\n",
    "ls = '-'\n",
    "lw = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pred Lag Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data_folds(args):\n",
    "    \"\"\"Aggregate encoding data\n",
    "\n",
    "    Args:\n",
    "        args (namespace): commandline arguments\n",
    "\n",
    "    Returns:\n",
    "        df (DataFrame): df with all encoding results\n",
    "    \"\"\"\n",
    "    print(\"Aggregating data\")\n",
    "\n",
    "    def read_file(fname):\n",
    "        files = glob.glob(fname)\n",
    "        assert (\n",
    "            len(files) > 0\n",
    "        ), f\"No results found under {fname}\"  # check files exist under format\n",
    "\n",
    "        for resultfn in files:\n",
    "            elec = os.path.basename(resultfn).replace(\".csv\", \"\")[:-10]\n",
    "            # Skip electrodes if they're not part of the sig list\n",
    "            if len(args.sigelecs) and elec not in args.sigelecs[(load_sid, key)]:\n",
    "                continue\n",
    "            df = pd.read_csv(resultfn, header=None)\n",
    "            df = df.iloc[[10]]\n",
    "            df.insert(0, \"sid\", load_sid)\n",
    "            df.insert(0, \"key\", key)\n",
    "            df.insert(0, \"electrode\", elec)\n",
    "            df.insert(0, \"label\", label)\n",
    "            data.append(df)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    if len(args.labels) / len(args.unique_labels) == len(args.sid):\n",
    "        for fmt, label in zip(args.formats, args.labels):\n",
    "            load_sid = get_sid(fmt, args)\n",
    "            for key in args.keys:\n",
    "                fname = fmt % key\n",
    "                read_file(fname)\n",
    "    else:\n",
    "        for load_sid in args.sid:\n",
    "            for fmt, label in zip(args.formats, args.labels):\n",
    "                for key in args.keys:\n",
    "                    fname = fmt % (load_sid, key)\n",
    "                    read_file(fname)\n",
    "\n",
    "    if not len(data):\n",
    "        print(\"No data found\")\n",
    "        exit(1)\n",
    "    df = pd.concat(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  project = \"tfs\"\n",
    "  formats = [ # encoding folder\n",
    "    # \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-encoder-lag2k-25-all-0/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-encoder-lag2k-25-all-4/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-decoder-nots-lag2k-25-all-noearlypca/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231108-whisper-acoustic/kw-tfs-full-%s-whisper-tiny.en-encoder-lag10k-25-all/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-encoder-lag10k-25-all/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20231118-decoder-ts-scare/kw-tfs-full-%s-whisper-tiny.en-decoder-nots-lag10k-25-all-noearlypca/*/*%s.csv\",\n",
    "  ]\n",
    "  labels = [\n",
    "    \"encoder\"\n",
    "  ]\n",
    "  sig_elec_file = [\"../data/plotting/sig-elecs/20230413-whisper-paper/tfs-sig-file-%(sid)s-whisper-de-last-0.01-%(key)s.csv\"]\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  layers = np.arange(0,25)\n",
    "  lags_plot = np.arange(-10000,10001,25) # encoding lags\n",
    "  lags_show = np.arange(-10000,10001,25) # lags for the effect\n",
    "  lc_by = \"labels\"\n",
    "  ls_by = \"keys\"\n",
    "\n",
    "# Aggregate Data\n",
    "args = Args()\n",
    "args.unique_labels = list(dict.fromkeys(args.labels))\n",
    "args.unique_keys = list(dict.fromkeys(args.keys))\n",
    "args.lags_show = args.lags_show / 1000\n",
    "args.lags_plot = args.lags_plot / 1000\n",
    "args = get_sigelecs(args)  # get significant electrodes\n",
    "\n",
    "# for item in args.sigelecs: # align prod/comp elecs\n",
    "#     comp_set = set(args.sigelecs[(item[0], \"comp\")])\n",
    "#     prod_set = set(args.sigelecs[(item[0], \"prod\")])\n",
    "#     args.sigelecs[item] = comp_set.union(prod_set)\n",
    "\n",
    "df = aggregate_data(args) # aggregate data\n",
    "df = organize_data(args, df) # trim data if necessary\n",
    "df.sort_index(level=[3,1,2], ascending=True, inplace=True)\n",
    "df = df.droplevel(\"label\")\n",
    "df[\"max\"] = df.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  project = \"tfs\"\n",
    "  formats = [ # encoding folder\n",
    "    # \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-encoder-lag2k-25-all-0-pred-lag/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-encoder-lag2k-25-all-pred-lag/*/*%s.csv\",\n",
    "    \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-decoder-nots-lag2k-25-all-noearlypca-pred-lag/*/*%s.csv\",\n",
    "  ]\n",
    "  labels = [\n",
    "    \"pred-lag\"\n",
    "  ]\n",
    "  sig_elec_file = [\"../data/plotting/sig-elecs/20230413-whisper-paper/tfs-sig-file-%(sid)s-whisper-de-last-0.01-%(key)s.csv\"]\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  layers = np.arange(0,25)\n",
    "  lags_plot = np.arange(0,1,1) # encoding lags\n",
    "  lags_show = np.arange(0,1,1) # lags for the effect\n",
    "  lc_by = \"labels\"\n",
    "  ls_by = \"keys\"\n",
    "\n",
    "# Aggregate Data\n",
    "args = Args()\n",
    "args.unique_labels = list(dict.fromkeys(args.labels))\n",
    "args.unique_keys = list(dict.fromkeys(args.keys))\n",
    "args.lags_show = args.lags_show / 1000\n",
    "args.lags_plot = args.lags_plot / 1000\n",
    "args = get_sigelecs(args)  # get significant electrodes\n",
    "\n",
    "df2 = aggregate_data(args) # aggregate data\n",
    "df2 = organize_data(args, df2) # trim data if necessary\n",
    "df2[\"max\"] = df2.max(axis=1)\n",
    "\n",
    "df2.sort_index(level=[3,1,2], ascending=True, inplace=True)\n",
    "df2 = df2.droplevel(\"label\")\n",
    "df2.loc[:,\"original\"] = df[\"max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_comp = df2.loc[df2.index.get_level_values(\"key\") == \"comp\"]\n",
    "df2_prod = df2.loc[df2.index.get_level_values(\"key\") == \"prod\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(df2_comp[\"original\"], df2_comp[\"max\"],s=3)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes)\n",
    "ax.set_ylim(0,0.4)\n",
    "ax.set_xlim(0,0.4)\n",
    "plt.savefig(f\"../de-comp.svg\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(df2_prod[\"original\"], df2_prod[\"max\"],s=3)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes)\n",
    "ax.set_ylim(0,0.4)\n",
    "ax.set_xlim(0,0.4)\n",
    "plt.savefig(f\"../de-prod.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binsize & Samplesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  project = \"tfs\"\n",
    "  formats = [ # encoding folder\n",
    "    \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-encoder-lag10k-25-all/*/*_%s.csv\",\n",
    "    \"../data/encoding/tfs/20231004-whisper-binsize/kw-tfs-full-%s-whisper-tiny.en-encoder-lag10k-25-all-100/*/*_%s.csv\",\n",
    "    \"../data/encoding/tfs/20231004-whisper-binsize/kw-tfs-full-%s-whisper-tiny.en-encoder-lag10k-25-all-50/*/*_%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231004-whisper-binsize/kw-tfs-full-%s-whisper-tiny.en-decoder-lag10k-25-all-noearlypca/*/*_%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231004-whisper-binsize/kw-tfs-full-%s-whisper-tiny.en-decoder-lag10k-25-all-noearlypca-100/*/*_%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231004-whisper-binsize/kw-tfs-full-%s-whisper-tiny.en-decoder-lag10k-25-all-noearlypca-50/*/*_%s.csv\",\n",
    "  ]\n",
    "  labels = [\n",
    "    \"win-200\",\n",
    "    \"win-100\",\n",
    "    \"win-050\"\n",
    "  ]\n",
    "  sig_elec_file = [\"../data/plotting/sig-elecs/20230413-whisper-paper/tfs-sig-file-%(sid)s-whisper-en-last-0.01-%(key)s.csv\"]\n",
    "  # sig_elec_file = [\"../data/plotting/sig-elecs/20230413-whisper-paper/tfs-sig-file-%(sid)s-whisper-de-best-0.01-%(key)s.csv\"]\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  layers = np.arange(0,25)\n",
    "  lags_plot = np.arange(-10000,10001,25) # encoding lags\n",
    "  lags_show = np.arange(-2000,2001,25) # lags for the effect\n",
    "  lc_by = \"labels\"\n",
    "  ls_by = \"keys\"\n",
    "\n",
    "# Aggregate Data\n",
    "args = Args()\n",
    "args.unique_labels = list(dict.fromkeys(args.labels))\n",
    "args.unique_keys = list(dict.fromkeys(args.keys))\n",
    "args.lags_show = args.lags_show / 1000\n",
    "args.lags_plot = args.lags_plot / 1000\n",
    "args = get_sigelecs(args)  # get significant electrodes\n",
    "colors = get_cat_color()\n",
    "styles = [\"-\", \"-\", \"-\", \"-\"]\n",
    "cmap = {}  # line color map\n",
    "smap = {}  # line style map\n",
    "for label, color in zip(args.unique_labels, colors):\n",
    "  for key, style in zip(args.unique_keys, styles):\n",
    "    cmap[(label, key)] = color\n",
    "    smap[(label, key)] = style\n",
    "args.cmap = cmap\n",
    "args.smap = smap\n",
    "\n",
    "df = aggregate_data(args) # aggregate data\n",
    "df = organize_data(args, df) # trim data if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  project = \"tfs\"\n",
    "  formats = [ # encoding folder\n",
    "    # \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-encoder-lag10k-25-all/*/*_%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231018-whisper-sample-size/kw-tfs-full-%s-whisper-tiny.en-encoder-lag10k-25-half/*/*_%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231018-whisper-sample-size/kw-tfs-full-%s-whisper-tiny.en-encoder-lag10k-25-quarter/*/*_%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231018-whisper-sample-size/kw-tfs-full-%s-whisper-tiny.en-encoder-lag10k-25-tenth/*/*_%s.csv\",\n",
    "    \"../data/encoding/tfs/20231004-whisper-binsize/kw-tfs-full-%s-whisper-tiny.en-decoder-lag10k-25-all-noearlypca/*/*_%s.csv\",\n",
    "    \"../data/encoding/tfs/20231018-whisper-sample-size/kw-tfs-full-%s-whisper-tiny.en-decoder-lag10k-25-half/*/*_%s.csv\",\n",
    "    \"../data/encoding/tfs/20231018-whisper-sample-size/kw-tfs-full-%s-whisper-tiny.en-decoder-lag10k-25-quarter/*/*_%s.csv\",\n",
    "    \"../data/encoding/tfs/20231018-whisper-sample-size/kw-tfs-full-%s-whisper-tiny.en-decoder-lag10k-25-tenth/*/*_%s.csv\",\n",
    "  ]\n",
    "  labels = [\n",
    "    \"all\",\n",
    "    \"half\",\n",
    "    \"quarter\",\n",
    "    \"tenth\"\n",
    "  ]\n",
    "  # sig_elec_file = [\"../data/plotting/sig-elecs/20230413-whisper-paper/tfs-sig-file-%(sid)s-whisper-en-last-0.01-%(key)s.csv\"]\n",
    "  sig_elec_file = [\"../data/plotting/sig-elecs/20230413-whisper-paper/tfs-sig-file-%(sid)s-whisper-de-best-0.01-%(key)s.csv\"]\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  layers = np.arange(0,25)\n",
    "  lags_plot = np.arange(-10000,10001,25) # encoding lags\n",
    "  lags_show = np.arange(-2000,2001,25) # lags for the effect\n",
    "  lc_by = \"labels\"\n",
    "  ls_by = \"keys\"\n",
    "\n",
    "# Aggregate Data\n",
    "args = Args()\n",
    "args.unique_labels = list(dict.fromkeys(args.labels))\n",
    "args.unique_keys = list(dict.fromkeys(args.keys))\n",
    "args.lags_show = args.lags_show / 1000\n",
    "args.lags_plot = args.lags_plot / 1000\n",
    "args = get_sigelecs(args)  # get significant electrodes\n",
    "colors = get_cat_color()\n",
    "styles = [\"-\", \"-\", \"-\", \"-\"]\n",
    "cmap = {}  # line color map\n",
    "smap = {}  # line style map\n",
    "for label, color in zip(args.unique_labels, colors):\n",
    "  for key, style in zip(args.unique_keys, styles):\n",
    "    cmap[(label, key)] = color\n",
    "    smap[(label, key)] = style\n",
    "args.cmap = cmap\n",
    "args.smap = smap\n",
    "\n",
    "df = aggregate_data(args) # aggregate data\n",
    "df = organize_data(args, df) # trim data if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for plot, subdf in df.groupby(\"key\", axis=0):\n",
    "    fig, ax = plt.subplots()\n",
    "    for line, subsubdf in subdf.groupby(\"label\", axis=0):\n",
    "        vals = subsubdf.mean(axis=0)\n",
    "        err = subsubdf.sem(axis=0)\n",
    "        map_key = (line, plot)\n",
    "        ax.fill_between(\n",
    "            args.lags_show,\n",
    "            vals - err,\n",
    "            vals + err,\n",
    "            alpha=0.2,\n",
    "            color=args.cmap[map_key],\n",
    "        )\n",
    "        ax.plot(\n",
    "            args.lags_show,\n",
    "            vals,\n",
    "            label=f\"{line} ({len(subsubdf)})\",\n",
    "            color=args.cmap[map_key],\n",
    "            ls=args.smap[map_key],\n",
    "        )\n",
    "        ax.axhline(0, ls=\"dashed\", alpha=0.3, c=\"k\")\n",
    "        ax.axvline(0, ls=\"dashed\", alpha=0.3, c=\"k\")\n",
    "        ax.set_title(f\"{plot} global average\")\n",
    "        ax.legend(loc=\"upper right\", frameon=False)\n",
    "        ax.set(xlabel=\"Lag (s)\", ylabel=\"Correlation (r)\")\n",
    "        plt.savefig(f\"../de-samplesize-{plot}.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_df(label):  # get partial df\n",
    "    idx = pd.IndexSlice\n",
    "    part_df = df.loc[idx[label, :, :, :], :].copy()\n",
    "    part_df.index = part_df.index.droplevel(\"label\")\n",
    "    part_df_idx = part_df.index.get_level_values(\"electrode\").tolist()\n",
    "    return part_df, part_df_idx\n",
    "\n",
    "df1, df1_idx = get_part_df(\"all\")\n",
    "df2, df2_idx = get_part_df(\"quarter\")\n",
    "df1[\"max\"] = df1.max(axis=1)\n",
    "df2[\"max\"] = df2.max(axis=1)\n",
    "df1.sort_index(level=[2,0,1], ascending=True, inplace=True)\n",
    "df2.sort_index(level=[2,0,1], ascending=True, inplace=True)\n",
    "df1[\"max-quarter\"] = df2[\"max\"]\n",
    "df1_comp = df1.loc[df1.index.get_level_values(\"key\") == \"comp\"]\n",
    "df1_prod = df1.loc[df1.index.get_level_values(\"key\") == \"prod\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(df1_comp[\"max\"], df1_comp[\"max-quarter\"],s=3)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes)\n",
    "ax.set_ylim(0,0.4)\n",
    "ax.set_xlim(0,0.4)\n",
    "plt.savefig(f\"../quarter-comp.svg\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(df1_prod[\"max\"], df1_prod[\"max-quarter\"],s=3)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes)\n",
    "ax.set_ylim(0,0.4)\n",
    "ax.set_xlim(0,0.4)\n",
    "plt.savefig(f\"../quarter-prod.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Ceiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data_ceiling(args, row_num, label_name):\n",
    "    print(\"Aggregating data\")\n",
    "\n",
    "    def read_file(fname, row_num, label):\n",
    "        files = glob.glob(fname)\n",
    "        assert (\n",
    "            len(files) > 0\n",
    "        ), f\"No results found under {fname}\"  # check files exist under format\n",
    "\n",
    "        for resultfn in files:\n",
    "            elec = os.path.basename(resultfn).replace(\".csv\", \"\")[:-5]\n",
    "            # Skip electrodes if they're not part of the sig list\n",
    "            if len(args.sigelecs) and elec not in args.sigelecs[(load_sid, key)]:\n",
    "                continue\n",
    "            df = pd.read_csv(resultfn, header=None)\n",
    "            df = df.iloc[[row_num]]\n",
    "            df.insert(0, \"sid\", load_sid)\n",
    "            df.insert(0, \"key\", key)\n",
    "            df.insert(0, \"electrode\", elec)\n",
    "            df.insert(0, \"label\", label)\n",
    "            data.append(df)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    if len(args.labels) / len(args.unique_labels) == len(args.sid):\n",
    "        for fmt, label in zip(args.formats, args.labels):\n",
    "            load_sid = get_sid(fmt, args)\n",
    "            for key in args.keys:\n",
    "                fname = fmt % key\n",
    "                read_file(fname, row_num, label_name)\n",
    "    else:\n",
    "        for load_sid in args.sid:\n",
    "            for fmt, label in zip(args.formats, args.labels):\n",
    "                for key in args.keys:\n",
    "                    fname = fmt % (load_sid, key)\n",
    "                    read_file(fname, row_num, label_name)\n",
    "\n",
    "    if not len(data):\n",
    "        print(\"No data found\")\n",
    "        exit(1)\n",
    "    df = pd.concat(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  sid = [625, 676, 7170, 798] # subjects\n",
    "  project = \"tfs\"\n",
    "  formats = [ # encoding folder\n",
    "    \"../data/encoding/tfs/20231221-noise/kw-tfs-full-%s-whisper-tiny.en-decoder-nots-lag10k-25-all-noise-ceiling/*/*%s.csv\",\n",
    "  ]\n",
    "  labels = [\n",
    "    \"noise\"\n",
    "  ]\n",
    "  sig_elec_file = []\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  layers = np.arange(0,25)\n",
    "  lags_plot = np.arange(-10000,10001,25) # encoding lags\n",
    "  lags_show = np.arange(-10000,10001,25) # lags for the effect\n",
    "  lc_by = \"labels\"\n",
    "  ls_by = \"keys\"\n",
    "\n",
    "# Aggregate Data\n",
    "args = Args()\n",
    "args.unique_labels = list(dict.fromkeys(args.labels))\n",
    "args.unique_keys = list(dict.fromkeys(args.keys))\n",
    "args.lags_show = args.lags_show / 1000\n",
    "args.lags_plot = args.lags_plot / 1000\n",
    "args = get_sigelecs(args)  # get significant electrodes\n",
    "\n",
    "# df1 = aggregate_data_ceiling(args, 0 ,\"min\") # aggregate data\n",
    "# df2 = aggregate_data_ceiling(args, 1 ,\"25\") # aggregate data\n",
    "# df3 = aggregate_data_ceiling(args, 2 ,\"50\") # aggregate data\n",
    "# df4 = aggregate_data_ceiling(args, 3 ,\"75\") # aggregate data\n",
    "# df5 = aggregate_data_ceiling(args, 4 ,\"max\") # aggregate data\n",
    "# df6 = aggregate_data_ceiling(args, 5 ,\"mean\") # aggregate data\n",
    "# df7 = aggregate_data_ceiling(args, 6 ,\"std\") # aggregate data\n",
    "# df8 = aggregate_data_ceiling(args, 7 ,\"sem\") # aggregate data\n",
    "\n",
    "save_path = \"../data/plotting/paper-whisper/data/noise_ceiling/\"\n",
    "# df1.to_csv(os.path.join(save_path, \"min.csv\"),index=False)\n",
    "# df2.to_csv(os.path.join(save_path, \"25.csv\"),index=False)\n",
    "# df3.to_csv(os.path.join(save_path, \"50.csv\"),index=False)\n",
    "# df4.to_csv(os.path.join(save_path, \"75.csv\"),index=False)\n",
    "# df5.to_csv(os.path.join(save_path, \"max.csv\"),index=False)\n",
    "# df6.to_csv(os.path.join(save_path, \"mean.csv\"),index=False)\n",
    "# df7.to_csv(os.path.join(save_path, \"std.csv\"),index=False)\n",
    "# df8.to_csv(os.path.join(save_path, \"sem.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,20))\n",
    "\n",
    "modes = [\"min\",\"25\",\"50\",\"75\",\"max\",\"mean\"]\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "]\n",
    "\n",
    "for mode, color in zip(modes, colors):\n",
    "    df = pd.read_csv(os.path.join(save_path, f\"{mode}.csv\"))\n",
    "    df = organize_data(args, df) # trim data if necessary\n",
    "    means = df.mean(axis=0)\n",
    "    sems = df.sem(axis=0)\n",
    "\n",
    "    ax.fill_between(\n",
    "        args.lags_show,\n",
    "        means - sems,\n",
    "        means + sems,\n",
    "        alpha=0.2,\n",
    "        color=color,\n",
    "    )\n",
    "    ax.plot(\n",
    "        args.lags_show,\n",
    "        means,\n",
    "        label=mode,\n",
    "        color=color,\n",
    "        ls=\"-\",\n",
    "    )\n",
    "    ax.legend(loc=\"upper right\", frameon=False)\n",
    "plt.savefig(\"noise.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Minute Brainmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  main_dir = \"../data/plotting/brainplot/\" # loads coordinate and brain surface files\n",
    "  project = \"tfs\"\n",
    "  sid = [625,676,7170,798] # subjects\n",
    "  formats = [ # encoding folder\n",
    "    \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-encoder-lag2k-25-all-0-pred-lag/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-encoder-lag2k-25-all-pred-lag/*/*%s.csv\",\n",
    "    # \"../data/encoding/tfs/20231121-pick-lag/kw-tfs-full-%s-whisper-tiny.en-decoder-nots-lag2k-25-all-noearlypca-pred-lag/*/*%s.csv\",\n",
    "  ]\n",
    "  labels = [\n",
    "    \"pred-lag\"\n",
    "  ]\n",
    "  sig_elec_file = [\"../data/plotting/sig-elecs/20230413-whisper-paper/tfs-sig-file-%(sid)s-whisper-en-first-0.01-%(key)s.csv\"]\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  layers = np.arange(0,25)\n",
    "  lags_plot = np.arange(0,1,1) # encoding lags\n",
    "  lags_show = np.arange(0,1,1) # lags for the effect\n",
    "  lc_by = \"labels\"\n",
    "  ls_by = \"keys\"\n",
    "  brain_type = \"ave\" # average brain\n",
    "  hemisphere = \"both\" # only plot left hemisphere\n",
    "  outfile = \"../tfs_%s.svg\"\n",
    "  final = True\n",
    "  final2 = False\n",
    "  shiny = False\n",
    "\n",
    "args = Args()\n",
    "args.color_split = [Colorbar(bar_min=0.04, bar_max=0.4)]\n",
    "args.unique_labels = list(dict.fromkeys(args.labels))\n",
    "args.unique_keys = list(dict.fromkeys(args.keys))\n",
    "args.lags_show = args.lags_show / 1000\n",
    "args.lags_plot = args.lags_plot / 1000\n",
    "args = get_sigelecs(args)  # get significant electrodes\n",
    "\n",
    "df = aggregate_data(args) # aggregate data\n",
    "df = organize_data(args, df) # trim data if necessary\n",
    "df[\"effect\"] = df.max(axis=1)\n",
    "df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "fig = make_brainmap(args, df.loc[df.key==\"comp\",(\"electrode\",\"effect\")], args.outfile % \"comp\") # plot png\n",
    "fig = make_brainmap(args, df.loc[df.key==\"prod\",(\"electrode\",\"effect\")], args.outfile % \"prod\") # plot png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  main_dir = \"../data/plotting/brainplot/\" # loads coordinate and brain surface files\n",
    "  project = \"tfs\"\n",
    "  sid = [625,676,7170,798] # subjects\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  brain_type = \"ave\" # average brain\n",
    "  hemisphere = \"both\" # only plot left hemisphere\n",
    "  outfile = \"../tfs_%s.svg\"\n",
    "  final = True\n",
    "  final2 = False\n",
    "  shiny = False\n",
    "\n",
    "args = Args()\n",
    "\n",
    "pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, \"#ffffff\"],[1, \"#ea0071\"]],bar_min=0,bar_max=0.05)\n",
    "neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, \"#0000ff\"],[1, \"#ffffff\"]],bar_min=-0.05,bar_max=0)\n",
    "args.color_split = [neg_bar,0,pos_bar]\n",
    "\n",
    "df = pd.read_csv(\"/scratch/gpfs/ln1144/247-plotting/paper/materials/text_only_vs_text_audio_de_text_only_vs_text_audio_comp.csv\")\n",
    "df[\"electrode\"] = df.sid.astype(str) + \"_\" + df.elec_1\n",
    "fig = make_brainmap(args, df, args.outfile % \"comp\") # plot png\n",
    "df = pd.read_csv(\"/scratch/gpfs/ln1144/247-plotting/paper/materials/text_only_vs_text_audio_de_text_only_vs_text_audio_prod.csv\")\n",
    "df[\"electrode\"] = df.sid.astype(str) + \"_\" + df.elec_1\n",
    "fig = make_brainmap(args, df, args.outfile % \"prod\") # plot png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  main_dir = \"../data/plotting/brainplot/\" # loads coordinate and brain surface files\n",
    "  project = \"tfs\"\n",
    "  sid = [625,676,7170,798] # subjects\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  brain_type = \"ave\" # average brain\n",
    "  hemisphere = \"both\" # only plot left hemisphere\n",
    "  outfile = \"../tfs_%s.svg\"\n",
    "  final = True\n",
    "  final2 = False\n",
    "  shiny = False\n",
    "\n",
    "args = Args()\n",
    "# Green & Purple whisper\n",
    "# pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, \"#00fa9a\"],[1, \"#006400\"]],bar_min=0.01,bar_max=0.15)\n",
    "pos_bar = Colorbar(title=\"Δ corr pos\",colorscale=[[0, \"#ee82ee\"],[1, \"#800080\"]],bar_min=0.01,bar_max=0.15)\n",
    "neg_bar = Colorbar(title=\"Δ corr neg\",colorscale=[[0, \"#006400\"],[1, \"#00fa9a\"]],bar_min=-0.15,bar_max=-0.01)\n",
    "args.color_split = [neg_bar,0,pos_bar]\n",
    "\n",
    "df = pd.read_csv(\"/scratch/gpfs/ln1144/247-plotting/paper/materials/prod_comp_contrast/prod_comp_encoder.csv\")\n",
    "df[\"electrode\"] = df.sid.astype(str) + \"_\" + df.elec_1\n",
    "fig = make_brainmap(args, df, args.outfile % \"en\") # plot png\n",
    "df = pd.read_csv(\"/scratch/gpfs/ln1144/247-plotting/paper/materials/prod_comp_contrast/prod_comp_decoder.csv\")\n",
    "df[\"electrode\"] = df.sid.astype(str) + \"_\" + df.elec_1\n",
    "fig = make_brainmap(args, df, args.outfile % \"de\") # plot png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  main_dir = \"../data/plotting/brainplot/\" # loads coordinate and brain surface files\n",
    "  project = \"tfs\"\n",
    "  sid = [625,676,7170,798] # subjects\n",
    "  keys = [\"comp\",\"prod\"] # comprehension and/or production\n",
    "  brain_type = \"ave\" # average brain\n",
    "  hemisphere = \"both\" # only plot left hemisphere\n",
    "  outfile = \"../tfs_%s.svg\"\n",
    "  final = True\n",
    "  final2 = False\n",
    "  shiny = False\n",
    "\n",
    "args = Args()\n",
    "# args.color_split = [Colorbar(title=\"Corr\",colorscale=[[0, \"#ffffff\"],[1, \"#ff0000\"]],bar_min=0,bar_max=1)]\n",
    "args.color_split = [Colorbar(title=\"Corr\",colorscale=[[0, \"#ffffff\"],[1, \"#0000ff\"]],bar_min=0,bar_max=1)]\n",
    "\n",
    "# df = pd.read_csv(\"/scratch/gpfs/ln1144/247-plotting/paper/materials/pc_flip/pc_flip_encoder.csv\")\n",
    "# df[\"electrode\"] = df.sid.astype(str) + \"_\" + df.elec_1\n",
    "# fig = make_brainmap(args, df, args.outfile % \"en\") # plot png\n",
    "df = pd.read_csv(\"/scratch/gpfs/ln1144/247-plotting/paper/materials/pc_flip/pc_flip_decoder.csv\")\n",
    "df[\"electrode\"] = df.sid.astype(str) + \"_\" + df.elec_1\n",
    "fig = make_brainmap(args, df, args.outfile % \"de\") # plot png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
